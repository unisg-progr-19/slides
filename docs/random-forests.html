<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Random Forests | 7784 Skills: Programming in R</title>
  <meta name="description" content="9 Random Forests | 7784 Skills: Programming in R" />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Random Forests | 7784 Skills: Programming in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Random Forests | 7784 Skills: Programming in R" />
  
  
  

<meta name="author" content="Kirill Müller, Christoph Sax" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="transformation-3.html"/>

<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#using-left_join-to-join-data-sets"><i class="fa fa-check"></i><b>1.1</b> Using <code>left_join</code> to join data sets</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="visualization-and-reporting.html"><a href="visualization-and-reporting.html"><i class="fa fa-check"></i><b>2</b> Visualization and Reporting</a></li>
<li class="chapter" data-level="3" data-path="data-tranformation-i.html"><a href="data-tranformation-i.html"><i class="fa fa-check"></i><b>3</b> Data Tranformation I</a></li>
<li class="chapter" data-level="4" data-path="data-tranformation-ii.html"><a href="data-tranformation-ii.html"><i class="fa fa-check"></i><b>4</b> Data Tranformation II</a></li>
<li class="chapter" data-level="5" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html"><i class="fa fa-check"></i><b>5</b> Basics of R base</a><ul>
<li class="chapter" data-level="5.1" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#the-main-data-structures"><i class="fa fa-check"></i><b>5.1</b> The Main Data Structures</a><ul>
<li class="chapter" data-level="5.1.1" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#vectors-the-r-workhorse"><i class="fa fa-check"></i><b>5.1.1</b> Vectors, the R Workhorse</a></li>
<li class="chapter" data-level="5.1.2" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#matrices"><i class="fa fa-check"></i><b>5.1.2</b> Matrices</a></li>
<li class="chapter" data-level="5.1.3" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#lists"><i class="fa fa-check"></i><b>5.1.3</b> Lists</a></li>
<li class="chapter" data-level="5.1.4" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#data-frames"><i class="fa fa-check"></i><b>5.1.4</b> Data Frames</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#introduction-to-functions"><i class="fa fa-check"></i><b>5.2</b> Introduction to Functions</a><ul>
<li class="chapter" data-level="5.2.1" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#variable-scope"><i class="fa fa-check"></i><b>5.2.1</b> Variable Scope</a></li>
<li class="chapter" data-level="5.2.2" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#default-arguments"><i class="fa fa-check"></i><b>5.2.2</b> Default Arguments</a></li>
<li class="chapter" data-level="5.2.3" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#exercises-3"><i class="fa fa-check"></i><b>5.2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#higher-order-functions"><i class="fa fa-check"></i><b>5.3</b> Higher-Order Functions</a><ul>
<li class="chapter" data-level="5.3.1" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#map"><i class="fa fa-check"></i><b>5.3.1</b> <code>map</code></a></li>
<li class="chapter" data-level="5.3.2" data-path="basics-of-r-base.html"><a href="basics-of-r-base.html#loops"><i class="fa fa-check"></i><b>5.3.2</b> Loops</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="math-and-statistics.html"><a href="math-and-statistics.html"><i class="fa fa-check"></i><b>6</b> Math and Statistics</a><ul>
<li class="chapter" data-level="6.1" data-path="math-and-statistics.html"><a href="math-and-statistics.html#math"><i class="fa fa-check"></i><b>6.1</b> Math</a><ul>
<li class="chapter" data-level="6.1.1" data-path="math-and-statistics.html"><a href="math-and-statistics.html#basic-math-functions"><i class="fa fa-check"></i><b>6.1.1</b> Basic Math Functions</a></li>
<li class="chapter" data-level="6.1.2" data-path="math-and-statistics.html"><a href="math-and-statistics.html#linear-algebra-operations-on-vectors-and-matrices-optional"><i class="fa fa-check"></i><b>6.1.2</b> Linear Algebra Operations on Vectors and Matrices <em>(optional)</em></a></li>
<li class="chapter" data-level="6.1.3" data-path="math-and-statistics.html"><a href="math-and-statistics.html#statistical-distributions-optional"><i class="fa fa-check"></i><b>6.1.3</b> Statistical Distributions <em>(optional)</em></a></li>
<li class="chapter" data-level="6.1.4" data-path="math-and-statistics.html"><a href="math-and-statistics.html#set-operations-optional"><i class="fa fa-check"></i><b>6.1.4</b> Set Operations <em>(optional)</em></a></li>
<li class="chapter" data-level="6.1.5" data-path="math-and-statistics.html"><a href="math-and-statistics.html#exercises-4"><i class="fa fa-check"></i><b>6.1.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="math-and-statistics.html"><a href="math-and-statistics.html#linear-regression"><i class="fa fa-check"></i><b>6.2</b> Linear Regression</a><ul>
<li class="chapter" data-level="6.2.1" data-path="math-and-statistics.html"><a href="math-and-statistics.html#example-bootstrapping-standard-errors-optional"><i class="fa fa-check"></i><b>6.2.1</b> Example: Bootstrapping standard errors <em>(optional)</em></a></li>
<li class="chapter" data-level="6.2.2" data-path="math-and-statistics.html"><a href="math-and-statistics.html#factors-in-regression-models"><i class="fa fa-check"></i><b>6.2.2</b> Factors in regression models</a></li>
<li class="chapter" data-level="6.2.3" data-path="math-and-statistics.html"><a href="math-and-statistics.html#exercises-5"><i class="fa fa-check"></i><b>6.2.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="math-and-statistics.html"><a href="math-and-statistics.html#numerical-optimization-optional"><i class="fa fa-check"></i><b>6.3</b> Numerical Optimization <em>(optional)</em></a></li>
<li class="chapter" data-level="6.4" data-path="math-and-statistics.html"><a href="math-and-statistics.html#extended-exercises"><i class="fa fa-check"></i><b>6.4</b> Extended Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regression-and-visualization.html"><a href="regression-and-visualization.html"><i class="fa fa-check"></i><b>7</b> Regression and Visualization</a><ul>
<li class="chapter" data-level="7.1" data-path="regression-and-visualization.html"><a href="regression-and-visualization.html#the-broom-package"><i class="fa fa-check"></i><b>7.1</b> The broom package</a></li>
<li class="chapter" data-level="7.2" data-path="regression-and-visualization.html"><a href="regression-and-visualization.html#texreg-and-friends"><i class="fa fa-check"></i><b>7.2</b> texreg and friends</a></li>
<li class="chapter" data-level="7.3" data-path="regression-and-visualization.html"><a href="regression-and-visualization.html#from-data-frame-to-output-kable"><i class="fa fa-check"></i><b>7.3</b> From data frame to output: kable</a></li>
<li class="chapter" data-level="7.4" data-path="regression-and-visualization.html"><a href="regression-and-visualization.html#more-on-linear-regression"><i class="fa fa-check"></i><b>7.4</b> More on linear regression</a><ul>
<li class="chapter" data-level="7.4.1" data-path="regression-and-visualization.html"><a href="regression-and-visualization.html#relationship-between-class-size-and-test-score"><i class="fa fa-check"></i><b>7.4.1</b> Relationship between class size and test score</a></li>
<li class="chapter" data-level="7.4.2" data-path="regression-and-visualization.html"><a href="regression-and-visualization.html#heteroskedasticity-consistent-standard-errors"><i class="fa fa-check"></i><b>7.4.2</b> Heteroskedasticity-consistent standard errors</a></li>
<li class="chapter" data-level="7.4.3" data-path="regression-and-visualization.html"><a href="regression-and-visualization.html#omitted-variable-bias"><i class="fa fa-check"></i><b>7.4.3</b> Omitted variable bias</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="regression-and-visualization.html"><a href="regression-and-visualization.html#exercises-6"><i class="fa fa-check"></i><b>7.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="transformation-3.html"><a href="transformation-3.html"><i class="fa fa-check"></i><b>8</b> Transformation 3</a></li>
<li class="chapter" data-level="9" data-path="random-forests.html"><a href="random-forests.html"><i class="fa fa-check"></i><b>9</b> Random Forests</a><ul>
<li class="chapter" data-level="9.1" data-path="random-forests.html"><a href="random-forests.html#slang"><i class="fa fa-check"></i><b>9.1</b> Slang</a></li>
<li class="chapter" data-level="9.2" data-path="random-forests.html"><a href="random-forests.html#the-boston-housing-data-set-again"><i class="fa fa-check"></i><b>9.2</b> The Boston housing data set, again</a></li>
<li class="chapter" data-level="9.3" data-path="random-forests.html"><a href="random-forests.html#prediction-with-ols"><i class="fa fa-check"></i><b>9.3</b> Prediction with OLS</a></li>
<li class="chapter" data-level="9.4" data-path="random-forests.html"><a href="random-forests.html#decision-trees"><i class="fa fa-check"></i><b>9.4</b> Decision Trees</a></li>
<li class="chapter" data-level="9.5" data-path="random-forests.html"><a href="random-forests.html#random-forest"><i class="fa fa-check"></i><b>9.5</b> Random Forest</a><ul>
<li class="chapter" data-level="9.5.1" data-path="random-forests.html"><a href="random-forests.html#using-more-than-one-variable"><i class="fa fa-check"></i><b>9.5.1</b> Using more than one variable</a></li>
<li class="chapter" data-level="9.5.2" data-path="random-forests.html"><a href="random-forests.html#variable-importance"><i class="fa fa-check"></i><b>9.5.2</b> Variable importance</a></li>
<li class="chapter" data-level="9.5.3" data-path="random-forests.html"><a href="random-forests.html#exercises-7"><i class="fa fa-check"></i><b>9.5.3</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="random-forests.html"><a href="random-forests.html#classification"><i class="fa fa-check"></i><b>9.6</b> Classification</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">7784 Skills: Programming in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-forests" class="section level1">
<h1><span class="header-section-number">9</span> Random Forests</h1>
<p><a href="09-random-forest.R">Download as R script</a></p>
<p><a href="09-random-forest.html">Intro Slides</a></p>
<div id="slang" class="section level2">
<h2><span class="header-section-number">9.1</span> Slang</h2>
<table>
<colgroup>
<col width="70%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th>Econometrics</th>
<th>ML</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>sample data, to estimate the model</td>
<td>training sample</td>
</tr>
<tr class="even">
<td>estimating a model</td>
<td>training a model</td>
</tr>
<tr class="odd">
<td>regression parameters</td>
<td>weights</td>
</tr>
<tr class="even">
<td>regressor, predictor, independent variable, RHS</td>
<td>feature</td>
</tr>
<tr class="odd">
<td>estimating relationship between dependent var and regressors</td>
<td>supervised learning</td>
</tr>
<tr class="even">
<td>clustering</td>
<td>unsupervised learning</td>
</tr>
<tr class="odd">
<td>discrete response problems</td>
<td>classification problems</td>
</tr>
</tbody>
</table>
</div>
<div id="the-boston-housing-data-set-again" class="section level2">
<h2><span class="header-section-number">9.2</span> The Boston housing data set, again</h2>
<p>As in a previous exercise, we will work with Boston, which is part of the
<a href="https://cran.r-project.org/web/packages/MASS/index.html">MASS</a> package. The
data set was used in an <a href="https://www.sciencedirect.com/science/article/abs/pii/0095069678900062">1978
article</a>
on hedonic price estimation and the measurement for the demand for clean air.</p>
<p>For an explanation of variable names, check out the documentation:</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb308-1" data-line-number="1"><span class="co"># `?MASS::Boston`</span></a></code></pre></div>
<p>Again, we want to keep the data in a tibble, for convenience:</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb309-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb309-2" data-line-number="2">boston &lt;-<span class="st"> </span><span class="kw">as_tibble</span>(MASS<span class="op">::</span>Boston) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb309-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">chas =</span> <span class="kw">as.logical</span>(chas))</a></code></pre></div>
<p>Most predictive modeling is subject to the danger of overfitting. We will
discuss the concept later on. This means that a model can perform well in
within the sample it was estimated, but terrible, if it is applied to new
data. A popular way to control the problem is to estimate (train) the model
on a part of the original data only (e.g. 70%), and use the rest to test the
model afterwards.
To separate the dataset, we first add an ID column:</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb310-1" data-line-number="1">boston_with_id &lt;-</a>
<a class="sourceLine" id="cb310-2" data-line-number="2"><span class="st">  </span>boston <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb310-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">id =</span> <span class="kw">row_number</span>())</a></code></pre></div>
<p>The <code>sample_frac()</code> function allow as to pick a percentage of all rows from
the original dataset:</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb311-1" data-line-number="1">boston_train_with_id &lt;-<span class="st"> </span>boston_with_id <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb311-2" data-line-number="2"><span class="st">  </span><span class="kw">sample_frac</span>(<span class="fl">0.7</span>)</a>
<a class="sourceLine" id="cb311-3" data-line-number="3"></a>
<a class="sourceLine" id="cb311-4" data-line-number="4">boston_train &lt;-<span class="st"> </span>boston_train_with_id <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb311-5" data-line-number="5"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>id)</a></code></pre></div>
<p>This is the datset we will use for estimating our models. <code>anti_join()</code> can
be used to retrieve all rows that are not within <code>boston_train</code>, based on the
<code>id</code>:</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb312-1" data-line-number="1">boston_test &lt;-<span class="st"> </span>boston_with_id <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb312-2" data-line-number="2"><span class="st">  </span><span class="kw">anti_join</span>(boston_train_with_id, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb312-3" data-line-number="3"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>id)</a></code></pre></div>
<p>This is the datset we will use for evaluating our models.</p>
</div>
<div id="prediction-with-ols" class="section level2">
<h2><span class="header-section-number">9.3</span> Prediction with OLS</h2>
<p>We can use the OLS model to perform predictions of the median house value.
The OLS curve covers the predicted values of the model. Let’s recapitulate
and see, how the median value of owner-occupied homes, <code>medv</code>, can pe
predicted by the neighborhood, as measured by the percentage of lower status
population, <code>lstat</code>.</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb313-1" data-line-number="1">m_ols &lt;-<span class="st"> </span><span class="kw">lm</span>(medv <span class="op">~</span><span class="st"> </span>lstat, <span class="dt">data =</span> boston_train)</a>
<a class="sourceLine" id="cb313-2" data-line-number="2">boston_test <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb313-3" data-line-number="3"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predict =</span> <span class="kw">predict</span>(m_ols, <span class="dt">newdata =</span> boston_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb313-4" data-line-number="4"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lstat, <span class="dt">y =</span> medv)) <span class="op">+</span></a>
<a class="sourceLine" id="cb313-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb313-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> predict), <span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb313-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">xend =</span> lstat, <span class="dt">yend =</span> predict))</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-132-1.png" width="672" /></p>
</div>
<div id="decision-trees" class="section level2">
<h2><span class="header-section-number">9.4</span> Decision Trees</h2>
<p>A decision tree is tree-like structure of decisions and their possible
consequences. In a decision tree model, the prediction depends on particular
value of a variable. For example:</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb314-1" data-line-number="1"><span class="kw">library</span>(rpart)</a>
<a class="sourceLine" id="cb314-2" data-line-number="2">m_tree_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">rpart</span>(medv <span class="op">~</span><span class="st"> </span>lstat, <span class="dt">data =</span> boston_train, <span class="dt">method =</span> <span class="st">&quot;anova&quot;</span>, <span class="dt">maxdepth =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb314-3" data-line-number="3">m_tree_<span class="dv">1</span></a></code></pre></div>
<pre><code>## n= 354 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
## 1) root 354 31907.440 22.72684  
##   2) lstat&gt;=9.615 214  4907.116 17.42850 *
##   3) lstat&lt; 9.615 140 11809.990 30.82571 *</code></pre>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb316-1" data-line-number="1"><span class="kw">plot</span>(m_tree_<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb316-2" data-line-number="2"><span class="kw">text</span>(m_tree_<span class="dv">1</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-133-1.png" width="672" /></p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb317-1" data-line-number="1">boston_test <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb317-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predict =</span> <span class="kw">predict</span>(m_tree_<span class="dv">1</span>, <span class="dt">newdata =</span> boston_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb317-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lstat, <span class="dt">y =</span> medv)) <span class="op">+</span></a>
<a class="sourceLine" id="cb317-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb317-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> predict), <span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb317-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">xend =</span> lstat, <span class="dt">yend =</span> predict), <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb317-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> <span class="fl">9.95</span>))</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-133-2.png" width="672" /></p>
<p>More interesting trees can be grown if we increase the <em>depth</em> of a tree.
Here, we let the tree grow to a depths of 2, which allows for four possible
prediction values:</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb318-1" data-line-number="1">m_tree_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">rpart</span>(medv <span class="op">~</span><span class="st"> </span>lstat, <span class="dt">data =</span> boston_train, <span class="dt">method =</span> <span class="st">&quot;anova&quot;</span>, <span class="dt">maxdepth =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb318-2" data-line-number="2">m_tree_<span class="dv">2</span></a></code></pre></div>
<pre><code>## n= 354 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
## 1) root 354 31907.4400 22.72684  
##   2) lstat&gt;=9.615 214  4907.1160 17.42850  
##     4) lstat&gt;=15 118  2192.4100 14.83051 *
##     5) lstat&lt; 15 96   939.2841 20.62188 *
##   3) lstat&lt; 9.615 140 11809.9900 30.82571  
##     6) lstat&gt;=4.475 107  5141.7700 27.63738 *
##     7) lstat&lt; 4.475 33  2053.7160 41.16364 *</code></pre>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb320-1" data-line-number="1"><span class="kw">plot</span>(m_tree_<span class="dv">2</span>)</a>
<a class="sourceLine" id="cb320-2" data-line-number="2"><span class="kw">text</span>(m_tree_<span class="dv">2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-134-1.png" width="672" /></p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb321-1" data-line-number="1">boston_test <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb321-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predict =</span> <span class="kw">predict</span>(m_tree_<span class="dv">2</span>, <span class="dt">newdata =</span> boston_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb321-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lstat, <span class="dt">y =</span> medv)) <span class="op">+</span></a>
<a class="sourceLine" id="cb321-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb321-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> predict), <span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb321-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">xend =</span> lstat, <span class="dt">yend =</span> predict), <span class="dt">alpha =</span> <span class="fl">0.2</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb321-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> <span class="fl">4.295</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb321-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> <span class="fl">4.295</span>)) <span class="op">+</span></a>
<a class="sourceLine" id="cb321-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_vline</span>(<span class="kw">aes</span>(<span class="dt">xintercept =</span> <span class="dv">15</span>))</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-134-2.png" width="672" /></p>
<p>Analogous to multiple regression, we also can grow trees that depend on more
than variable. Here, our prediction depends both on the average number of
rooms per dwelling, <code>rm</code> and the percentage of lower status population
<code>lstat</code>.</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb322-1" data-line-number="1">m_tree_all &lt;-<span class="st"> </span><span class="kw">rpart</span>(medv <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> boston_train, <span class="dt">method =</span> <span class="st">&quot;anova&quot;</span>, <span class="dt">maxdepth =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb322-2" data-line-number="2">m_tree_all</a></code></pre></div>
<pre><code>## n= 354 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
## 1) root 354 31907.4400 22.72684  
##   2) lstat&gt;=9.615 214  4907.1160 17.42850  
##     4) lstat&gt;=15 118  2192.4100 14.83051 *
##     5) lstat&lt; 15 96   939.2841 20.62187 *
##   3) lstat&lt; 9.615 140 11809.9900 30.82571  
##     6) rm&lt; 7.437 117  5158.7180 27.87521 *
##     7) rm&gt;=7.437 23   451.4722 45.83478 *</code></pre>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb324-1" data-line-number="1"><span class="kw">plot</span>(m_tree_all)</a>
<a class="sourceLine" id="cb324-2" data-line-number="2"><span class="kw">text</span>(m_tree_all)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-135-1.png" width="672" /></p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb325-1" data-line-number="1">boston_test <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb325-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predict =</span> <span class="kw">predict</span>(m_tree_all, <span class="dt">newdata =</span> boston_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb325-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lstat, <span class="dt">y =</span> medv, <span class="dt">color =</span> rm)) <span class="op">+</span></a>
<a class="sourceLine" id="cb325-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb325-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> predict), <span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb325-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">xend =</span> lstat, <span class="dt">yend =</span> predict), <span class="dt">alpha =</span> <span class="fl">0.2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-135-2.png" width="672" /></p>
</div>
<div id="random-forest" class="section level2">
<h2><span class="header-section-number">9.5</span> Random Forest</h2>
<p>Random forest takes random subsets of data and train trees on each subset.
That is the reason behind the name for this method: random (subsets) forest
(trees). When predicting new data from the test set each tree produces its
own prediction. Then the predictions from all the trees are combined together
(averaged). This is why random forest can approximate linear patterns, even
when the single trees, as we saw above, only produce mean values for
different ranges of values.</p>
<p>The <em>randomForest</em> package offers basic random forest estimation in R:</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb326-1" data-line-number="1"><span class="kw">library</span>(randomForest)</a></code></pre></div>
<p>Because random forests are based on random sampling, setting the <em>seed</em> is
needed to make the estimation reproducible:</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb327-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">0</span>)</a></code></pre></div>
<p>Let’s start with a simple example:</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb328-1" data-line-number="1">m_forest &lt;-<span class="st"> </span><span class="kw">randomForest</span>(medv <span class="op">~</span><span class="st"> </span>lstat, <span class="dt">data =</span> boston_train)</a>
<a class="sourceLine" id="cb328-2" data-line-number="2"><span class="kw">plot</span>(m_forest)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-138-1.png" width="672" /></p>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb329-1" data-line-number="1">boston_test <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb329-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predict =</span> <span class="kw">predict</span>(m_forest, <span class="dt">newdata =</span> boston_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb329-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lstat, <span class="dt">y =</span> medv)) <span class="op">+</span></a>
<a class="sourceLine" id="cb329-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb329-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> predict), <span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb329-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">xend =</span> lstat, <span class="dt">yend =</span> predict), <span class="dt">alpha =</span> <span class="fl">0.2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-138-2.png" width="672" /></p>
<p>We now have a bunch of possible forecasts. Which one should you use. The
<em>Root Mean Squared Error</em>, while not the only possible measure, is usually a
good starting point. It’s main characteristics are the following:</p>
<ol style="list-style-type: decimal">
<li>Squared - so negative values become positive (deviation is deviation)</li>
<li>Squared - so large deviations are extra-penalized</li>
<li>Mean - influence of all errors are summarized with one number</li>
<li>Root - to go back to original scale after squaring.</li>
</ol>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb330-1" data-line-number="1">boston_test <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb330-2" data-line-number="2"><span class="st">  </span><span class="kw">summarize</span>(</a>
<a class="sourceLine" id="cb330-3" data-line-number="3">    <span class="dt">rmse_forest =</span> <span class="kw">sqrt</span>(<span class="kw">mean</span>((medv <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(m_forest, <span class="dt">newdata =</span> boston_test))<span class="op">^</span><span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb330-4" data-line-number="4">    <span class="dt">rmse_tree_1 =</span> <span class="kw">sqrt</span>(<span class="kw">mean</span>((medv <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(m_tree_<span class="dv">1</span>, <span class="dt">newdata =</span> boston_test))<span class="op">^</span><span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb330-5" data-line-number="5">    <span class="dt">rmse_ols =</span> <span class="kw">sqrt</span>(<span class="kw">mean</span>((medv <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(m_ols, <span class="dt">newdata =</span> boston_test))<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb330-6" data-line-number="6">  )</a></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   rmse_forest rmse_tree_1 rmse_ols
##         &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;
## 1        5.33        6.94     5.75</code></pre>
<div id="using-more-than-one-variable" class="section level3">
<h3><span class="header-section-number">9.5.1</span> Using more than one variable</h3>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb332-1" data-line-number="1"><span class="kw">library</span>(randomForest)</a>
<a class="sourceLine" id="cb332-2" data-line-number="2">m_forest_all &lt;-<span class="st"> </span><span class="kw">randomForest</span>(medv <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> boston_train)</a>
<a class="sourceLine" id="cb332-3" data-line-number="3"></a>
<a class="sourceLine" id="cb332-4" data-line-number="4">boston_test <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb332-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predict =</span> <span class="kw">predict</span>(m_forest_all, <span class="dt">newdata =</span> boston_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb332-6" data-line-number="6"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lstat, <span class="dt">y =</span> medv)) <span class="op">+</span></a>
<a class="sourceLine" id="cb332-7" data-line-number="7"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb332-8" data-line-number="8"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> predict), <span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb332-9" data-line-number="9"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">xend =</span> lstat, <span class="dt">yend =</span> predict), <span class="dt">alpha =</span> <span class="fl">0.2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-140-1.png" width="672" /></p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb333-1" data-line-number="1">m_ols_all &lt;-<span class="st"> </span><span class="kw">lm</span>(medv <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> boston_train)</a>
<a class="sourceLine" id="cb333-2" data-line-number="2"><span class="kw">summary</span>(m_ols_all)</a></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = medv ~ ., data = boston_train)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -10.0156  -2.9634  -0.5869   2.1585  25.2777 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  44.590000   6.526979   6.832 3.89e-11 ***
## crim         -0.149666   0.039656  -3.774 0.000189 ***
## zn            0.059000   0.016785   3.515 0.000499 ***
## indus         0.008600   0.073542   0.117 0.906976    
## chasTRUE      4.457064   1.206543   3.694 0.000257 ***
## nox         -20.069362   4.775555  -4.203 3.38e-05 ***
## rm            3.435511   0.544755   6.307 8.87e-10 ***
## age          -0.000949   0.016257  -0.058 0.953487    
## dis          -1.756968   0.245438  -7.159 5.06e-12 ***
## rad           0.337495   0.077762   4.340 1.88e-05 ***
## tax          -0.013745   0.004314  -3.186 0.001574 ** 
## ptratio      -1.034316   0.159799  -6.473 3.37e-10 ***
## black         0.006549   0.003247   2.017 0.044507 *  
## lstat        -0.544976   0.062931  -8.660  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.855 on 340 degrees of freedom
## Multiple R-squared:  0.7489, Adjusted R-squared:  0.7392 
## F-statistic: 77.98 on 13 and 340 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb335-1" data-line-number="1">boston_test <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb335-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">predict =</span> <span class="kw">predict</span>(m_ols_all, <span class="dt">newdata =</span> boston_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb335-3" data-line-number="3"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> lstat, <span class="dt">y =</span> medv)) <span class="op">+</span></a>
<a class="sourceLine" id="cb335-4" data-line-number="4"><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb335-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">y =</span> predict), <span class="dt">shape =</span> <span class="dv">21</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb335-6" data-line-number="6"><span class="st">  </span><span class="kw">geom_segment</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">xend =</span> lstat, <span class="dt">yend =</span> predict), <span class="dt">alpha =</span> <span class="fl">0.2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-140-2.png" width="672" /></p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb336-1" data-line-number="1">boston_test <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb336-2" data-line-number="2"><span class="st">  </span><span class="kw">summarize</span>(</a>
<a class="sourceLine" id="cb336-3" data-line-number="3">    <span class="dt">rmse_forest =</span> <span class="kw">sqrt</span>(<span class="kw">sum</span>((medv <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(m_forest, <span class="dt">newdata =</span> boston_test))<span class="op">^</span><span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb336-4" data-line-number="4">    <span class="dt">rmse_tree_1 =</span> <span class="kw">sqrt</span>(<span class="kw">sum</span>((medv <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(m_tree_<span class="dv">1</span>, <span class="dt">newdata =</span> boston_test))<span class="op">^</span><span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb336-5" data-line-number="5">    <span class="dt">rmse_ols =</span> <span class="kw">sqrt</span>(<span class="kw">sum</span>((medv <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(m_ols, <span class="dt">newdata =</span> boston_test))<span class="op">^</span><span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb336-6" data-line-number="6">    <span class="dt">rmse_ols_all =</span> <span class="kw">sqrt</span>(<span class="kw">sum</span>((medv <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(m_ols_all, <span class="dt">newdata =</span> boston_test))<span class="op">^</span><span class="dv">2</span>)),</a>
<a class="sourceLine" id="cb336-7" data-line-number="7">    <span class="dt">rmse_forest_all =</span> <span class="kw">sqrt</span>(<span class="kw">sum</span>((medv <span class="op">-</span><span class="st"> </span><span class="kw">predict</span>(m_forest_all, <span class="dt">newdata =</span> boston_test))<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb336-8" data-line-number="8">  )</a></code></pre></div>
<pre><code>## # A tibble: 1 x 5
##   rmse_forest rmse_tree_1 rmse_ols rmse_ols_all rmse_forest_all
##         &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;           &lt;dbl&gt;
## 1        65.8        85.5     70.9         58.0            34.8</code></pre>
<p>If the interactions between features are mostly linear (as modeled by linear
regression) then random forest will not beat linear regression no matter
how much data it will have. However if there are interactions in the data the
linear model will require for you to list them in the formula (<code>y ~ x1 * x2</code>)
and random forest would be able to find them on its own.</p>
</div>
<div id="variable-importance" class="section level3">
<h3><span class="header-section-number">9.5.2</span> Variable importance</h3>
<p>So we have used OLS, decision trees and random forest to explain the values of
<code>medv</code>. But which independent variables are the most important? We have many
variables, and would like to rank them by importance. How can we do that?
For <strong>OLS</strong>, the importance can be obtained by the p-value. According to this,
<code>lstat</code> and <code>rm</code> are the most important variables:</p>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb338-1" data-line-number="1">broom<span class="op">::</span><span class="kw">tidy</span>(m_ols_all) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb338-2" data-line-number="2"><span class="st">  </span><span class="kw">arrange</span>(p.value)</a></code></pre></div>
<pre><code>## # A tibble: 14 x 5
##    term          estimate std.error statistic  p.value
##    &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 lstat        -0.545      0.0629    -8.66   1.93e-16
##  2 dis          -1.76       0.245     -7.16   5.06e-12
##  3 (Intercept)  44.6        6.53       6.83   3.89e-11
##  4 ptratio      -1.03       0.160     -6.47   3.37e-10
##  5 rm            3.44       0.545      6.31   8.87e-10
##  6 rad           0.337      0.0778     4.34   1.88e- 5
##  7 nox         -20.1        4.78      -4.20   3.38e- 5
##  8 crim         -0.150      0.0397    -3.77   1.89e- 4
##  9 chasTRUE      4.46       1.21       3.69   2.57e- 4
## 10 zn            0.0590     0.0168     3.52   4.99e- 4
## 11 tax          -0.0137     0.00431   -3.19   1.57e- 3
## 12 black         0.00655    0.00325    2.02   4.45e- 2
## 13 indus         0.00860    0.0735     0.117  9.07e- 1
## 14 age          -0.000949   0.0163    -0.0584 9.53e- 1</code></pre>
<p>For <strong>single trees</strong>, the values that split the data at the highest level
should be more important. Again, <code>lstat</code> and <code>rm</code> are the most important
variables:</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb340-1" data-line-number="1">m_tree_all</a></code></pre></div>
<pre><code>## n= 354 
## 
## node), split, n, deviance, yval
##       * denotes terminal node
## 
## 1) root 354 31907.4400 22.72684  
##   2) lstat&gt;=9.615 214  4907.1160 17.42850  
##     4) lstat&gt;=15 118  2192.4100 14.83051 *
##     5) lstat&lt; 15 96   939.2841 20.62187 *
##   3) lstat&lt; 9.615 140 11809.9900 30.82571  
##     6) rm&lt; 7.437 117  5158.7180 27.87521 *
##     7) rm&gt;=7.437 23   451.4722 45.83478 *</code></pre>
<p>For <strong>random forest</strong>, there are several different measures of variable
importance. We will focus on one of them, the <em>decrease in accuracy</em>. It
measures the percentage of accuracy decrease if one variable is omitted. To
calculate this measure of importance - we need to add <code>importance = TRUE</code> to
our model call:</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb342-1" data-line-number="1">m_forest_all &lt;-<span class="st"> </span><span class="kw">randomForest</span>(medv <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> boston_train, <span class="dt">importance =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p><code>varImpPlot()</code> gives a convenient overview of variable importance, <code>type = 1</code>
selects the measure of importance, here, the mean decrease in accuracy after
permutation:</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb343-1" data-line-number="1"><span class="kw">varImpPlot</span>(m_forest_all, <span class="dt">type =</span> <span class="dv">1</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-144-1.png" width="672" /></p>
<p>Again <code>lstat</code> and <code>rm</code> are the most important variables, but <code>rm</code> seems to be
substantially more important than <code>lstat</code>.</p>
</div>
<div id="exercises-7" class="section level3">
<h3><span class="header-section-number">9.5.3</span> Exercises</h3>
<p>Back to the <code>CASchools</code> dataset on test performance, school characteristics
and student demographic backgrounds for school districts in California. As
before, we will enhance the dataset by defining two new variables,
<code>student_teacher_ratio</code>, the student-teacher ratio, and <code>test_score</code>, an
average of two underlying test scores:</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb344-1" data-line-number="1"><span class="kw">library</span>(AER)</a>
<a class="sourceLine" id="cb344-2" data-line-number="2"><span class="kw">data</span>(CASchools)</a>
<a class="sourceLine" id="cb344-3" data-line-number="3"></a>
<a class="sourceLine" id="cb344-4" data-line-number="4">caschools &lt;-</a>
<a class="sourceLine" id="cb344-5" data-line-number="5"><span class="st">  </span>CASchools <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb344-6" data-line-number="6"><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb344-7" data-line-number="7"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">student_teacher_ratio =</span> students <span class="op">/</span><span class="st"> </span>teachers) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb344-8" data-line-number="8"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">test_score =</span> (read <span class="op">+</span><span class="st"> </span>math) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb344-9" data-line-number="9"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>read, <span class="op">-</span>math, <span class="op">-</span>students, <span class="op">-</span>teachers, <span class="op">-</span>district, <span class="op">-</span>school, <span class="op">-</span>county, <span class="op">-</span>grades)</a>
<a class="sourceLine" id="cb344-10" data-line-number="10"></a>
<a class="sourceLine" id="cb344-11" data-line-number="11">caschools</a></code></pre></div>
<pre><code>## # A tibble: 420 x 8
##    calworks  lunch computer expenditure income english student_teacher…
##       &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;            &lt;dbl&gt;
##  1    0.510   2.04       67       6385.  22.7     0                17.9
##  2   15.4    47.9       101       5099.   9.82    4.58             21.5
##  3   55.0    76.3       169       5502.   8.98   30.0              18.7
##  4   36.5    77.0        85       7102.   8.98    0                17.4
##  5   33.1    78.4       171       5236.   9.08   13.9              18.7
##  6   12.3    87.0        25       5580.  10.4    12.4              21.4
##  7   12.9    94.6        28       5253.   6.58   68.7              19.5
##  8   18.8   100          66       4566.   8.17   47.0              20.9
##  9   32.2    93.1        35       5356.   7.39   30.1              19.9
## 10   79.0    87.3         0       5036.  11.6    40.3              20.8
## # … with 410 more rows, and 1 more variable: test_score &lt;dbl&gt;</code></pre>
<ol style="list-style-type: decimal">
<li><p>Separate the data set into a training and a test set. Make sure the
training set contains 75% of the available observations.</p></li>
<li><p>Build a decision tree to predict <code>student_teacher_ratio</code>, using all
variables in <code>caschools_train</code>. Use the defaults of <code>rpart</code>. Draw the
resulting decision tree. Store the model as <code>m_tree</code>.</p></li>
<li><p>From the documentation, <code>?rpart</code>, can you figure out how the depth of a
tree is determined? Which one is the most important variable?</p></li>
<li><p>Estimate an OLS model to predict <code>student_teacher_ratio</code>, using all
variables in <code>caschools_train</code>. Which one is the most important variable?
Store the model as <code>m_ols</code>.</p></li>
<li><p>grow a random forest to predict <code>student_teacher_ratio</code>, using all
variables in <code>caschools_train</code>. Use the defaults of <code>randomForest</code>. Store the
model as <code>m_forest</code>.</p></li>
<li><p>Plot the variable importance for <code>m_forest</code>. Which one is the most
imporant?</p></li>
<li><p>Using the test data, can you compute RMSE measures for <code>m_ols</code>, <code>m_tree</code>,
and <code>m_forest</code>? Which performs best?</p></li>
</ol>
</div>
</div>
<div id="classification" class="section level2">
<h2><span class="header-section-number">9.6</span> Classification</h2>
<p>This data set provides information on the fate of passengers on the fatal
maiden voyage of the ocean liner Titanic, summarized according to economic
status (class), sex, age and survival. Titanic dataset is classic example in
machine learning, and can be found in the <em>titanic</em> package.</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb346-1" data-line-number="1"><span class="co"># install.packages(&quot;titanic&quot;)  # make sure it is installed.</span></a>
<a class="sourceLine" id="cb346-2" data-line-number="2"><span class="kw">head</span>(titanic<span class="op">::</span>titanic_train)</a></code></pre></div>
<pre><code>##   PassengerId Survived Pclass
## 1           1        0      3
## 2           2        1      1
## 3           3        1      3
## 4           4        1      1
## 5           5        0      3
## 6           6        0      3
##                                                  Name    Sex Age SibSp Parch
## 1                             Braund, Mr. Owen Harris   male  22     1     0
## 2 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female  38     1     0
## 3                              Heikkinen, Miss. Laina female  26     0     0
## 4        Futrelle, Mrs. Jacques Heath (Lily May Peel) female  35     1     0
## 5                            Allen, Mr. William Henry   male  35     0     0
## 6                                    Moran, Mr. James   male  NA     0     0
##             Ticket    Fare Cabin Embarked
## 1        A/5 21171  7.2500              S
## 2         PC 17599 71.2833   C85        C
## 3 STON/O2. 3101282  7.9250              S
## 4           113803 53.1000  C123        S
## 5           373450  8.0500              S
## 6           330877  8.4583              Q</code></pre>
<p>The goal of the exercise it to predict survival. The datasets come divided
into training and testing set. However, the testing part does not have
survival information and is not useful that way. In the following, we will
limit ourself to the <code>titanic::titanic_train</code>.</p>
<p>Categorical variables will be a problem in random forest, so we will convert
them into factors. We also clean up the data and remove missing values. The
cleaned dataset looks as follows:</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb348-1" data-line-number="1">titanic &lt;-</a>
<a class="sourceLine" id="cb348-2" data-line-number="2"><span class="st">  </span><span class="kw">as_tibble</span>(<span class="kw">na.omit</span>(titanic<span class="op">::</span>titanic_train)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb348-3" data-line-number="3"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>Name, <span class="op">-</span>PassengerId, <span class="op">-</span>Cabin, <span class="op">-</span>Ticket, <span class="op">-</span>Embarked) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb348-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Sex =</span> <span class="kw">as_factor</span>(Sex)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb348-5" data-line-number="5"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Survived =</span> <span class="kw">as_factor</span>(Survived))</a></code></pre></div>
<dl>
<dt><code>Survived</code></dt>
<dd>Passenger Survival Indicator
</dd>
<dt><code>Pclass</code></dt>
<dd>Passenger Class
</dd>
<dt><code>Sex</code></dt>
<dd>Sex
</dd>
<dt><code>Age</code></dt>
<dd>Age
</dd>
<dt><code>SibSp</code></dt>
<dd>Number of Siblings/Spouses Aboard
</dd>
<dt><code>Parch</code></dt>
<dd>Number of Parents/Children Aboard
</dd>
</dl>
<p>Again, the usual separation in test and training data set.</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb349-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb349-2" data-line-number="2">titanic_with_id &lt;-</a>
<a class="sourceLine" id="cb349-3" data-line-number="3"><span class="st">  </span>titanic <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb349-4" data-line-number="4"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">id =</span> <span class="kw">row_number</span>())</a>
<a class="sourceLine" id="cb349-5" data-line-number="5"></a>
<a class="sourceLine" id="cb349-6" data-line-number="6">titanic_train_with_id &lt;-</a>
<a class="sourceLine" id="cb349-7" data-line-number="7"><span class="st">  </span>titanic_with_id <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb349-8" data-line-number="8"><span class="st">  </span><span class="kw">sample_frac</span>(<span class="fl">0.70</span>)</a>
<a class="sourceLine" id="cb349-9" data-line-number="9"></a>
<a class="sourceLine" id="cb349-10" data-line-number="10">titanic_train &lt;-</a>
<a class="sourceLine" id="cb349-11" data-line-number="11"><span class="st">  </span>titanic_train_with_id <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb349-12" data-line-number="12"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>id)</a>
<a class="sourceLine" id="cb349-13" data-line-number="13"></a>
<a class="sourceLine" id="cb349-14" data-line-number="14">titanic_test &lt;-</a>
<a class="sourceLine" id="cb349-15" data-line-number="15"><span class="st">  </span>titanic_with_id <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb349-16" data-line-number="16"><span class="st">  </span><span class="kw">anti_join</span>(titanic_train_with_id, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb349-17" data-line-number="17"><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>id)</a></code></pre></div>
<p>To start, let’s build a decision tree:</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb350-1" data-line-number="1">m_titanic_tree &lt;-<span class="st"> </span><span class="kw">rpart</span>(Survived <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> titanic_train)</a>
<a class="sourceLine" id="cb350-2" data-line-number="2"><span class="kw">plot</span>(m_titanic_tree)</a>
<a class="sourceLine" id="cb350-3" data-line-number="3"><span class="kw">text</span>(m_titanic_tree, <span class="dt">all =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-149-1.png" width="672" /></p>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb351-1" data-line-number="1">m_titanic_tree</a></code></pre></div>
<pre><code>## n= 500 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##   1) root 500 203 0 (0.59400000 0.40600000)  
##     2) Sex=male 319  62 0 (0.80564263 0.19435737)  
##       4) Pclass&gt;=1.5 248  35 0 (0.85887097 0.14112903)  
##         8) Age&gt;=9.5 227  25 0 (0.88986784 0.11013216) *
##         9) Age&lt; 9.5 21  10 0 (0.52380952 0.47619048)  
##          18) SibSp&gt;=2.5 11   0 0 (1.00000000 0.00000000) *
##          19) SibSp&lt; 2.5 10   0 1 (0.00000000 1.00000000) *
##       5) Pclass&lt; 1.5 71  27 0 (0.61971831 0.38028169)  
##        10) Age&gt;=36.5 45  12 0 (0.73333333 0.26666667) *
##        11) Age&lt; 36.5 26  11 1 (0.42307692 0.57692308)  
##          22) Fare&gt;=61.8 11   4 0 (0.63636364 0.36363636) *
##          23) Fare&lt; 61.8 15   4 1 (0.26666667 0.73333333) *
##     3) Sex=female 181  40 1 (0.22099448 0.77900552)  
##       6) Pclass&gt;=2.5 65  31 0 (0.52307692 0.47692308)  
##        12) Fare&gt;=20.8 15   2 0 (0.86666667 0.13333333) *
##        13) Fare&lt; 20.8 50  21 1 (0.42000000 0.58000000)  
##          26) Age&gt;=17.5 36  17 0 (0.52777778 0.47222222)  
##            52) Fare&lt; 15 29  12 0 (0.58620690 0.41379310)  
##             104) Fare&gt;=8.29375 16   4 0 (0.75000000 0.25000000) *
##             105) Fare&lt; 8.29375 13   5 1 (0.38461538 0.61538462) *
##            53) Fare&gt;=15 7   2 1 (0.28571429 0.71428571) *
##          27) Age&lt; 17.5 14   2 1 (0.14285714 0.85714286) *
##       7) Pclass&lt; 2.5 116   6 1 (0.05172414 0.94827586) *</code></pre>
<p>This has a very simple interpretation: If you are on the Titanic, the best
guess is that you will die. If you are male, things look bad, unless you are
a child. If you are female, things look better, especially if you travel
first class. So it is not very hard to guess the end of the movie <em>Titanic</em>.</p>
<p>Switching to random forest, the output now includes the a <em>confusion matrix</em>.
The confusion matrix shows, based on out-of-bag evaluation, which
classification has been done correctly and which has not. 270 deaths has been
predicted correctly, 151 survivals have been predicted correctly. On the
other hand, 27 dying passengers have been incorrectly predicted to survive,
while 52 surviving passengers have been incorrectly predicted to to die.</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb353-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb353-2" data-line-number="2">m_titanic_forest &lt;-<span class="st"> </span><span class="kw">randomForest</span>(Survived <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> titanic_train, <span class="dt">importance =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb353-3" data-line-number="3">m_titanic_forest</a></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = Survived ~ ., data = titanic_train, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 15.8%
## Confusion matrix:
##     0   1 class.error
## 0 270  27  0.09090909
## 1  52 151  0.25615764</code></pre>
<p>The out-of-bag forecast error are usually a good way to quickly assess the
forecast accuracy of a random forest model. However, if we want to run the
model on our test data, compute the confusion table as follows:</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb355-1" data-line-number="1"><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb355-2" data-line-number="2">  <span class="dt">predicted =</span> <span class="kw">predict</span>(m_titanic_forest, <span class="dt">newdata =</span> titanic_test),</a>
<a class="sourceLine" id="cb355-3" data-line-number="3">  <span class="dt">actual =</span> titanic_test<span class="op">$</span>Survived</a>
<a class="sourceLine" id="cb355-4" data-line-number="4">) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb355-5" data-line-number="5"><span class="st">  </span><span class="kw">group_by</span>(predicted, actual) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb355-6" data-line-number="6"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>())</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
## # Groups:   predicted [2]
##   predicted actual count
##   &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;
## 1 0         0        107
## 2 0         1         26
## 3 1         0         20
## 4 1         1         61</code></pre>
<p>The corresponding out-of-bag confusion table as is as follows:</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb357-1" data-line-number="1"><span class="kw">tibble</span>(</a>
<a class="sourceLine" id="cb357-2" data-line-number="2">  <span class="dt">predicted =</span> <span class="kw">predict</span>(m_titanic_forest),</a>
<a class="sourceLine" id="cb357-3" data-line-number="3">  <span class="dt">actual =</span> titanic_train<span class="op">$</span>Survived</a>
<a class="sourceLine" id="cb357-4" data-line-number="4">) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb357-5" data-line-number="5"><span class="st">  </span><span class="kw">group_by</span>(predicted, actual) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb357-6" data-line-number="6"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">count =</span> <span class="kw">n</span>())</a></code></pre></div>
<pre><code>## # A tibble: 4 x 3
## # Groups:   predicted [2]
##   predicted actual count
##   &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;
## 1 0         0        270
## 2 0         1         52
## 3 1         0         27
## 4 1         1        151</code></pre>
<p>Finally, which variables are the important one?</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb359-1" data-line-number="1"><span class="kw">varImpPlot</span>(m_titanic_forest, <span class="dt">type =</span> <span class="dv">1</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-153-1.png" width="672" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="transformation-3.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
